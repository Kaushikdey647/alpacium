{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Backtesting StockLLM Alpha on US Mega-cap Tech (Daily)\n",
        "\n",
        "Pipeline:\n",
        "- Fetch last 5 years of daily bars from Alpaca for 10 large-cap US tech stocks\n",
        "- Build a FAISS candidate index using the first 4 years (2020-01 to 2023-12) with paper-aligned indicators (OHLCV + RSI + MACD_hist)\n",
        "- Run the StockLLM alpha on the last 1 year (2024-01 to 2024-12) only\n",
        "- Backtest with vectorbt and run analytics (performance, hit rate, per-symbol breakdown, calibration/Brier)\n",
        "\n",
        "Notes:\n",
        "- Requires `alpaca-py`, `transformers`, `torch`, and `faiss-cpu` (CPU fallback for FAISS implemented)\n",
        "- StockLLM and FinSeer models will be downloaded on first run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-10 02:05:27,601 | INFO | src.utils.logging: Logging configured: level=INFO rich=False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.utils.logging import configure_logging\n",
        "configure_logging(level=\"INFO\", use_rich=False)\n",
        "\n",
        "from src.schemas import TimeFrame\n",
        "from src.adapters.alpaca_data import AlpacaMarketData, AlpacaMarketDataConfig\n",
        "from src.retrieval.finseer_client import FinSeerEmbedder, FinSeerConfig\n",
        "from src.retrieval.faiss_index import FaissCandidateIndex, default_indicator_builder\n",
        "from src.llm.stockllm_client import StockLLMGenerator, StockLLMConfig\n",
        "from src.alphas.stockllm_alpha import stockllm_alpha\n",
        "from src.engines.alpha_engine import AlphaEngine\n",
        "from src.engines.vbt_engine import run_backtest_vbt\n",
        "\n",
        "# Prefer cuVS-like GPU index when available; fallback to FAISS\n",
        "try:\n",
        "    from src.retrieval.cuvs_index import CuVSLikeCandidateIndex as _CuIndex\n",
        "    _HAS_CUVS = True\n",
        "except Exception:\n",
        "    _HAS_CUVS = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-10 02:06:23,106 | INFO | src.adapters.alpaca_data: Fetching bars: symbols=['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'AVGO', 'ORCL', 'CRM'] timeframe=TimeFrame.day start=2020-01-01 00:00:00 end=2024-12-31 00:00:00 limit=None adjustment=None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Alpaca API key=True secret=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-10 02:06:33,579 | INFO | src.adapters.alpaca_data: Timezone normalized for bars: intraday=False tz=None tz_naive=True\n",
            "2025-08-10 02:06:33,586 | INFO | src.adapters.alpaca_data: Prepared symbol=NVDA rows=1257 cols=6\n",
            "2025-08-10 02:06:33,588 | INFO | src.adapters.alpaca_data: Prepared symbol=AAPL rows=1257 cols=6\n",
            "2025-08-10 02:06:33,591 | INFO | src.adapters.alpaca_data: Prepared symbol=AMZN rows=1257 cols=6\n",
            "2025-08-10 02:06:33,597 | INFO | src.adapters.alpaca_data: Prepared symbol=AVGO rows=1257 cols=6\n",
            "2025-08-10 02:06:33,600 | INFO | src.adapters.alpaca_data: Prepared symbol=CRM rows=1257 cols=6\n",
            "2025-08-10 02:06:33,604 | INFO | src.adapters.alpaca_data: Prepared symbol=GOOGL rows=1257 cols=6\n",
            "2025-08-10 02:06:33,610 | INFO | src.adapters.alpaca_data: Prepared symbol=META rows=1257 cols=6\n",
            "2025-08-10 02:06:33,615 | INFO | src.adapters.alpaca_data: Prepared symbol=MSFT rows=1257 cols=6\n",
            "2025-08-10 02:06:33,619 | INFO | src.adapters.alpaca_data: Prepared symbol=ORCL rows=1257 cols=6\n",
            "2025-08-10 02:06:33,623 | INFO | src.adapters.alpaca_data: Prepared symbol=TSLA rows=1257 cols=6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetched 10 symbols: ['NVDA', 'AAPL', 'AMZN', 'AVGO', 'CRM', 'GOOGL', 'META', 'MSFT', 'ORCL', 'TSLA']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'NVDA':                        open    high       low   close  adjusted_close  \\\n",
              " timestamp                                                               \n",
              " 2020-01-02 05:00:00  238.75  239.91  236.7200  239.91          239.91   \n",
              " 2020-01-03 05:00:00  235.10  237.83  234.1000  236.07          236.07   \n",
              " 2020-01-06 05:00:00  232.32  237.27  231.2700  237.06          237.06   \n",
              " 2020-01-07 05:00:00  238.20  241.77  236.3900  239.93          239.93   \n",
              " 2020-01-08 05:00:00  239.76  242.04  238.1490  240.38          240.38   \n",
              " ...                     ...     ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  136.28  139.79  135.1201  139.67          139.67   \n",
              " 2024-12-24 05:00:00  140.00  141.90  138.6500  140.22          140.22   \n",
              " 2024-12-26 05:00:00  139.70  140.85  137.7300  139.93          139.93   \n",
              " 2024-12-27 05:00:00  138.55  139.02  134.7100  137.01          137.01   \n",
              " 2024-12-30 05:00:00  134.83  140.27  134.0200  137.49          137.49   \n",
              " \n",
              "                           volume  \n",
              " timestamp                         \n",
              " 2020-01-02 05:00:00    6283815.0  \n",
              " 2020-01-03 05:00:00    5488864.0  \n",
              " 2020-01-06 05:00:00    7222529.0  \n",
              " 2020-01-07 05:00:00    8436402.0  \n",
              " 2020-01-08 05:00:00    7524829.0  \n",
              " ...                          ...  \n",
              " 2024-12-23 05:00:00  176053506.0  \n",
              " 2024-12-24 05:00:00  105156989.0  \n",
              " 2024-12-26 05:00:00  116519090.0  \n",
              " 2024-12-27 05:00:00  170582603.0  \n",
              " 2024-12-30 05:00:00  167734700.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'AAPL':                        open      high      low   close  adjusted_close  \\\n",
              " timestamp                                                                \n",
              " 2020-01-02 05:00:00  296.24  300.6000  295.190  300.35          300.35   \n",
              " 2020-01-03 05:00:00  297.15  300.5800  296.500  297.43          297.43   \n",
              " 2020-01-06 05:00:00  293.79  299.9600  292.750  299.80          299.80   \n",
              " 2020-01-07 05:00:00  299.84  300.9000  297.480  298.39          298.39   \n",
              " 2020-01-08 05:00:00  297.16  304.4399  297.156  303.19          303.19   \n",
              " ...                     ...       ...      ...     ...             ...   \n",
              " 2024-12-23 05:00:00  254.77  255.6500  253.450  255.27          255.27   \n",
              " 2024-12-24 05:00:00  255.49  258.2100  255.290  258.20          258.20   \n",
              " 2024-12-26 05:00:00  258.19  260.1000  257.630  259.02          259.02   \n",
              " 2024-12-27 05:00:00  257.83  258.7000  253.060  255.59          255.59   \n",
              " 2024-12-30 05:00:00  252.23  253.5000  250.750  252.20          252.20   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00  36554338.0  \n",
              " 2020-01-03 05:00:00  38677814.0  \n",
              " 2020-01-06 05:00:00  31399992.0  \n",
              " 2020-01-07 05:00:00  29556784.0  \n",
              " 2020-01-08 05:00:00  35684201.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  40858774.0  \n",
              " 2024-12-24 05:00:00  23234705.0  \n",
              " 2024-12-26 05:00:00  27262983.0  \n",
              " 2024-12-27 05:00:00  42355321.0  \n",
              " 2024-12-30 05:00:00  35557542.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'AMZN':                         open       high        low    close  adjusted_close  \\\n",
              " timestamp                                                                     \n",
              " 2020-01-02 05:00:00  1875.00  1898.0100  1864.1500  1898.01         1898.01   \n",
              " 2020-01-03 05:00:00  1864.50  1886.1965  1864.5000  1874.97         1874.97   \n",
              " 2020-01-06 05:00:00  1860.00  1903.6900  1860.0000  1902.88         1902.88   \n",
              " 2020-01-07 05:00:00  1904.50  1913.8900  1892.0433  1906.86         1906.86   \n",
              " 2020-01-08 05:00:00  1898.04  1910.9999  1886.4448  1891.97         1891.97   \n",
              " ...                      ...        ...        ...      ...             ...   \n",
              " 2024-12-23 05:00:00   225.01   226.8800   223.9000   225.06          225.06   \n",
              " 2024-12-24 05:00:00   226.94   229.1400   226.1300   229.05          229.05   \n",
              " 2024-12-26 05:00:00   228.50   228.5000   226.6706   227.05          227.05   \n",
              " 2024-12-27 05:00:00   225.60   226.0300   220.9000   223.75          223.75   \n",
              " 2024-12-30 05:00:00   220.06   222.9972   218.4300   221.30          221.30   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00   4384573.0  \n",
              " 2020-01-03 05:00:00   4030013.0  \n",
              " 2020-01-06 05:00:00   4395944.0  \n",
              " 2020-01-07 05:00:00   4370295.0  \n",
              " 2020-01-08 05:00:00   3725828.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  28070007.0  \n",
              " 2024-12-24 05:00:00  15007497.0  \n",
              " 2024-12-26 05:00:00  16174500.0  \n",
              " 2024-12-27 05:00:00  27367147.0  \n",
              " 2024-12-30 05:00:00  28321240.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'AVGO':                         open      high       low   close  adjusted_close  \\\n",
              " timestamp                                                                  \n",
              " 2020-01-02 05:00:00  319.320  322.5000  317.3184  322.39          322.39   \n",
              " 2020-01-03 05:00:00  317.510  320.0000  314.0800  314.19          314.19   \n",
              " 2020-01-06 05:00:00  310.845  313.9200  309.6250  313.72          313.72   \n",
              " 2020-01-07 05:00:00  315.250  316.5765  312.2500  312.64          312.64   \n",
              " 2020-01-08 05:00:00  312.980  313.4907  308.4100  308.74          308.74   \n",
              " ...                      ...       ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  226.690  233.3994  225.1300  232.35          232.35   \n",
              " 2024-12-24 05:00:00  240.115  240.2280  234.8000  239.68          239.68   \n",
              " 2024-12-26 05:00:00  240.000  247.2800  237.6000  245.36          245.36   \n",
              " 2024-12-27 05:00:00  245.640  245.7800  236.3532  241.75          241.75   \n",
              " 2024-12-30 05:00:00  234.695  238.7700  231.6200  235.58          235.58   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00   2171082.0  \n",
              " 2020-01-03 05:00:00   2561964.0  \n",
              " 2020-01-06 05:00:00   2692547.0  \n",
              " 2020-01-07 05:00:00   2037680.0  \n",
              " 2020-01-08 05:00:00   3516915.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  40643778.0  \n",
              " 2024-12-24 05:00:00  22827188.0  \n",
              " 2024-12-26 05:00:00  28537540.0  \n",
              " 2024-12-27 05:00:00  29282230.0  \n",
              " 2024-12-30 05:00:00  27316797.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'CRM':                        open      high       low   close  adjusted_close  \\\n",
              " timestamp                                                                 \n",
              " 2020-01-02 05:00:00  163.92  167.0700  163.5800  166.99          166.99   \n",
              " 2020-01-03 05:00:00  165.06  166.7700  165.0000  166.17          166.17   \n",
              " 2020-01-06 05:00:00  165.00  173.6700  164.4500  173.45          173.45   \n",
              " 2020-01-07 05:00:00  173.23  176.8700  172.0900  176.00          176.00   \n",
              " 2020-01-08 05:00:00  175.23  178.8500  174.7500  177.33          177.33   \n",
              " ...                     ...       ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  342.25  343.8457  336.6800  342.90          342.90   \n",
              " 2024-12-24 05:00:00  343.00  344.9500  340.8300  344.43          344.43   \n",
              " 2024-12-26 05:00:00  344.88  344.8800  341.0312  341.72          341.72   \n",
              " 2024-12-27 05:00:00  340.35  342.2700  335.2700  338.45          338.45   \n",
              " 2024-12-30 05:00:00  333.47  338.1078  331.6100  335.74          335.74   \n",
              " \n",
              "                         volume  \n",
              " timestamp                       \n",
              " 2020-01-02 05:00:00  5557042.0  \n",
              " 2020-01-03 05:00:00  3629836.0  \n",
              " 2020-01-06 05:00:00  9341626.0  \n",
              " 2020-01-07 05:00:00  8736076.0  \n",
              " 2020-01-08 05:00:00  7651211.0  \n",
              " ...                        ...  \n",
              " 2024-12-23 05:00:00  5330267.0  \n",
              " 2024-12-24 05:00:00  1810961.0  \n",
              " 2024-12-26 05:00:00  3484545.0  \n",
              " 2024-12-27 05:00:00  3220402.0  \n",
              " 2024-12-30 05:00:00  3411528.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'GOOGL':                         open      high        low    close  adjusted_close  \\\n",
              " timestamp                                                                    \n",
              " 2020-01-02 05:00:00  1348.41  1368.680  1346.4900  1368.68         1368.68   \n",
              " 2020-01-03 05:00:00  1348.00  1373.750  1347.3236  1361.52         1361.52   \n",
              " 2020-01-06 05:00:00  1351.63  1398.320  1351.0000  1397.81         1397.81   \n",
              " 2020-01-07 05:00:00  1400.46  1403.500  1391.5550  1395.11         1395.11   \n",
              " 2020-01-08 05:00:00  1394.82  1411.850  1392.6300  1405.04         1405.04   \n",
              " ...                      ...       ...        ...      ...             ...   \n",
              " 2024-12-23 05:00:00   192.62   195.100   190.1500   194.63          194.63   \n",
              " 2024-12-24 05:00:00   194.84   196.110   193.7800   196.11          196.11   \n",
              " 2024-12-26 05:00:00   195.15   196.748   194.3750   195.60          195.60   \n",
              " 2024-12-27 05:00:00   194.95   195.320   190.6500   192.76          192.76   \n",
              " 2024-12-30 05:00:00   189.80   192.550   189.1200   191.24          191.24   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00   1529285.0  \n",
              " 2020-01-03 05:00:00   1319940.0  \n",
              " 2020-01-06 05:00:00   2502731.0  \n",
              " 2020-01-07 05:00:00   1849019.0  \n",
              " 2020-01-08 05:00:00   1970053.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  25675014.0  \n",
              " 2024-12-24 05:00:00  10403259.0  \n",
              " 2024-12-26 05:00:00  12057210.0  \n",
              " 2024-12-27 05:00:00  18891362.0  \n",
              " 2024-12-30 05:00:00  14264659.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'META':                          open      high       low   close  adjusted_close  \\\n",
              " timestamp                                                                   \n",
              " 2020-01-02 05:00:00  206.7500  209.7900  206.2700  209.78          209.78   \n",
              " 2020-01-03 05:00:00  207.2135  210.4000  206.9500  208.67          208.67   \n",
              " 2020-01-06 05:00:00  206.9800  212.7800  206.5200  212.60          212.60   \n",
              " 2020-01-07 05:00:00  212.8200  214.5800  211.7500  213.06          213.06   \n",
              " 2020-01-08 05:00:00  213.0000  216.2400  212.6121  215.22          215.22   \n",
              " ...                       ...       ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  589.6000  601.0900  586.2500  599.85          599.85   \n",
              " 2024-12-24 05:00:00  602.7150  607.9900  599.2849  607.75          607.75   \n",
              " 2024-12-26 05:00:00  605.4800  606.3000  598.9400  603.35          603.35   \n",
              " 2024-12-27 05:00:00  599.4100  601.8500  589.8000  599.81          599.81   \n",
              " 2024-12-30 05:00:00  588.7500  596.9399  585.5800  591.24          591.24   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00  13280917.0  \n",
              " 2020-01-03 05:00:00  12292053.0  \n",
              " 2020-01-06 05:00:00  19695129.0  \n",
              " 2020-01-07 05:00:00  16084935.0  \n",
              " 2020-01-08 05:00:00  15168661.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  10205750.0  \n",
              " 2024-12-24 05:00:00   4726056.0  \n",
              " 2024-12-26 05:00:00   6091239.0  \n",
              " 2024-12-27 05:00:00   8084229.0  \n",
              " 2024-12-30 05:00:00   7025864.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'MSFT':                        open     high       low   close  adjusted_close  \\\n",
              " timestamp                                                                \n",
              " 2020-01-02 05:00:00  158.78  160.730  158.3300  160.62          160.62   \n",
              " 2020-01-03 05:00:00  158.32  159.945  158.0600  158.62          158.62   \n",
              " 2020-01-06 05:00:00  157.08  159.100  156.5100  159.03          159.03   \n",
              " 2020-01-07 05:00:00  159.32  159.670  157.3200  157.58          157.58   \n",
              " 2020-01-08 05:00:00  158.93  160.800  157.9491  160.09          160.09   \n",
              " ...                     ...      ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  436.74  437.650  432.8300  435.25          435.25   \n",
              " 2024-12-24 05:00:00  434.65  439.600  434.1900  439.33          439.33   \n",
              " 2024-12-26 05:00:00  439.08  440.940  436.6300  438.11          438.11   \n",
              " 2024-12-27 05:00:00  434.60  435.220  426.3500  430.53          430.53   \n",
              " 2024-12-30 05:00:00  426.06  427.550  421.9000  424.83          424.83   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00  25472631.0  \n",
              " 2020-01-03 05:00:00  24389239.0  \n",
              " 2020-01-06 05:00:00  24709110.0  \n",
              " 2020-01-07 05:00:00  24503429.0  \n",
              " 2020-01-08 05:00:00  31748417.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  19152519.0  \n",
              " 2024-12-24 05:00:00   7164543.0  \n",
              " 2024-12-26 05:00:00   8199927.0  \n",
              " 2024-12-27 05:00:00  18117713.0  \n",
              " 2024-12-30 05:00:00  13158703.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'ORCL':                        open    high       low   close  adjusted_close  \\\n",
              " timestamp                                                               \n",
              " 2020-01-02 05:00:00   53.23   53.96   53.2300   53.95           53.95   \n",
              " 2020-01-03 05:00:00   52.99   54.05   52.9500   53.76           53.76   \n",
              " 2020-01-06 05:00:00   53.36   54.20   53.3500   54.04           54.04   \n",
              " 2020-01-07 05:00:00   53.89   54.33   53.6100   54.16           54.16   \n",
              " 2020-01-08 05:00:00   53.94   54.60   53.7000   54.13           54.13   \n",
              " ...                     ...     ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  169.59  169.62  167.1683  169.14          169.14   \n",
              " 2024-12-24 05:00:00  169.70  171.77  169.0300  171.41          171.41   \n",
              " 2024-12-26 05:00:00  170.50  172.55  170.5000  171.68          171.68   \n",
              " 2024-12-27 05:00:00  170.38  171.15  167.2000  168.96          168.96   \n",
              " 2024-12-30 05:00:00  166.51  167.91  164.5500  166.91          166.91   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00  15422979.0  \n",
              " 2020-01-03 05:00:00  11957134.0  \n",
              " 2020-01-06 05:00:00  12441082.0  \n",
              " 2020-01-07 05:00:00  12837800.0  \n",
              " 2020-01-08 05:00:00  13261993.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00   6518229.0  \n",
              " 2024-12-24 05:00:00   2451547.0  \n",
              " 2024-12-26 05:00:00   4103882.0  \n",
              " 2024-12-27 05:00:00   4344287.0  \n",
              " 2024-12-30 05:00:00   5254833.0  \n",
              " \n",
              " [1257 rows x 6 columns],\n",
              " 'TSLA':                        open      high       low   close  adjusted_close  \\\n",
              " timestamp                                                                 \n",
              " 2020-01-02 05:00:00  424.50  430.6957  421.7100  430.26          430.26   \n",
              " 2020-01-03 05:00:00  440.50  454.0000  436.9200  443.01          443.01   \n",
              " 2020-01-06 05:00:00  440.47  451.5600  440.0000  451.50          451.50   \n",
              " 2020-01-07 05:00:00  461.40  471.6300  453.3550  469.06          469.06   \n",
              " 2020-01-08 05:00:00  473.70  498.4900  468.2300  492.14          492.14   \n",
              " ...                     ...       ...       ...     ...             ...   \n",
              " 2024-12-23 05:00:00  431.00  434.5100  415.4112  430.60          430.60   \n",
              " 2024-12-24 05:00:00  435.90  462.7800  435.1400  462.28          462.28   \n",
              " 2024-12-26 05:00:00  465.16  465.3299  451.0200  454.13          454.13   \n",
              " 2024-12-27 05:00:00  449.52  450.0000  426.5000  431.66          431.66   \n",
              " 2024-12-30 05:00:00  419.40  427.0000  415.7500  417.41          417.41   \n",
              " \n",
              "                          volume  \n",
              " timestamp                        \n",
              " 2020-01-02 05:00:00   9763456.0  \n",
              " 2020-01-03 05:00:00  18034327.0  \n",
              " 2020-01-06 05:00:00  10362505.0  \n",
              " 2020-01-07 05:00:00  18488930.0  \n",
              " 2020-01-08 05:00:00  31486817.0  \n",
              " ...                         ...  \n",
              " 2024-12-23 05:00:00  72698055.0  \n",
              " 2024-12-24 05:00:00  59551750.0  \n",
              " 2024-12-26 05:00:00  76651210.0  \n",
              " 2024-12-27 05:00:00  82666821.0  \n",
              " 2024-12-30 05:00:00  64941012.0  \n",
              " \n",
              " [1257 rows x 6 columns]}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 0) Symbols and date ranges\n",
        "symbols = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\",\n",
        "    \"META\", \"TSLA\", \"AVGO\", \"ORCL\", \"CRM\",\n",
        "]\n",
        "fetch_start = datetime(2020, 1, 1)\n",
        "fetch_end = datetime(2024, 12, 31)\n",
        "train_start = datetime(2020, 1, 1)\n",
        "train_end = datetime(2023, 12, 31)\n",
        "test_start = datetime(2024, 1, 1)\n",
        "test_end = datetime(2024, 12, 31)\n",
        "\n",
        "# 1) Fetch daily OHLCV from Alpaca\n",
        "# Reads keys from env (ALPACA_API_KEY, ALPACA_SECRET_KEY) or env.py if available\n",
        "api_key = os.getenv(\"ALPACA_API_KEY\")\n",
        "secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
        "if (api_key is None or secret_key is None):\n",
        "    try:\n",
        "        from env import paper_api_key as api_key, paper_secret_key as secret_key  # type: ignore\n",
        "    except Exception:\n",
        "        api_key = None\n",
        "        secret_key = None\n",
        "\n",
        "md = AlpacaMarketData(AlpacaMarketDataConfig(api_key=api_key, secret_key=secret_key, use_paper=True))\n",
        "print(f\"Using Alpaca API key={bool(api_key)} secret={bool(secret_key)}\")\n",
        "sym_to_df = md.get_stock_bars(\n",
        "    symbols=symbols,\n",
        "    timeframe=TimeFrame.day,\n",
        "    start=fetch_start,\n",
        "    end=fetch_end,\n",
        ")\n",
        "print(f\"Fetched {len(sym_to_df)} symbols: {[k for k in sym_to_df.keys()]}\")\n",
        "sym_to_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_span_days': 1461, 'test_span_days': 366, 'train_rows': 10060, 'test_rows': 2510}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filter to only symbols that returned data\n",
        "available_symbols = [s for s in symbols if s in sym_to_df and len(sym_to_df[s]) > 0]\n",
        "if len(available_symbols) < len(symbols):\n",
        "    missing = sorted(set(symbols) - set(available_symbols))\n",
        "    print(f\"Warning: missing data for symbols: {missing}\")\n",
        "\n",
        "# Combine to one MultiIndex DataFrame\n",
        "all_df = pd.concat({s: sym_to_df[s] for s in available_symbols}, names=[\"symbol\", \"timestamp\"]).sort_index()\n",
        "\n",
        "# 2) Split periods\n",
        "train_df = all_df.loc[(slice(None), slice(train_start, train_end)), :]\n",
        "test_df = all_df.loc[(slice(None), slice(test_start, test_end)), :]\n",
        "print({\n",
        "    \"train_span_days\": (train_end - train_start).days + 1,\n",
        "    \"test_span_days\": (test_end - test_start).days + 1,\n",
        "    \"train_rows\": len(train_df),\n",
        "    \"test_rows\": len(test_df),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at TheFinAI/FinSeer and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2025-08-10 02:06:44,402 | INFO | src.retrieval.cuvs_index: Using NumPy inner-product index (CPU) dim=768\n",
            "2025-08-10 02:06:44,404 | INFO | src.retrieval.cuvs_index: Loaded cuVS-like index from ./.alpacium_index (ids=8016 symbols=1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3) Build FinSeer index (prefer GPU CuPy index if available)\n",
        "embedder = FinSeerEmbedder(FinSeerConfig())\n",
        "if _HAS_CUVS:\n",
        "    index = _CuIndex(\n",
        "        embedder,\n",
        "        normalize=True,\n",
        "        use_gpu=True,\n",
        "        persist_dir=\"./.alpacium_index\",\n",
        "        auto_persist=True,\n",
        "    )\n",
        "else:\n",
        "    index = FaissCandidateIndex(\n",
        "        embedder,\n",
        "        normalize=True,\n",
        "        use_gpu=True,\n",
        "        persist_dir=\"./.alpacium_index\",\n",
        "        auto_persist=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72917de65dc34cb199aa41505206cab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Indexing symbols:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-10 02:07:09,587 | INFO | src.retrieval.faiss_index: Building candidates: symbol=AAPL rows=1006 indicators=['open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'RSI', 'MACD_hist'] lookback=5\n",
            "2025-08-10 02:07:14,861 | INFO | src.retrieval.faiss_index: Built 8016 candidates for symbol=AAPL\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f288ac914d64466a4c1fb9eeb9ec2b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Embedding batches:   0%|          | 0/251 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m added \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_from_symbol_dfs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mavailable_symbols\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlookback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindicator_builder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_indicator_builder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTimeFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m candidates from training period\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex size (ids) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index\u001b[38;5;241m.\u001b[39mid_to_meta)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; last dates per symbol = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(index\u001b[38;5;241m.\u001b[39msymbol_last_date\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/alpacium/src/retrieval/faiss_index.py:310\u001b[0m, in \u001b[0;36mFaissCandidateIndex.build_from_symbol_dfs\u001b[0;34m(self, symbol_to_df, lookback, indicator_builder, timeframe, show_progress)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sym, df \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    309\u001b[0m     cands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_candidates_for_symbol(sym, df, lookback, indicator_builder, timeframe)\n\u001b[0;32m--> 310\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total\n",
            "File \u001b[0;32m~/alpacium/src/retrieval/faiss_index.py:261\u001b[0m, in \u001b[0;36mFaissCandidateIndex.add_candidates\u001b[0;34m(self, cands, show_progress)\u001b[0m\n\u001b[1;32m    259\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m bs, \u001b[38;5;28mlen\u001b[39m(texts))\n\u001b[1;32m    260\u001b[0m chunk_texts \u001b[38;5;241m=\u001b[39m texts[start:end]\n\u001b[0;32m--> 261\u001b[0m vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m embedder_normalizes:\n\u001b[1;32m    264\u001b[0m     norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vecs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/alpacium/src/retrieval/finseer_client.py:81\u001b[0m, in \u001b[0;36mFinSeerEmbedder.encode\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     79\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menc)\n\u001b[1;32m     80\u001b[0m pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state, enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# (B, H)\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mpooled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[1;32m     83\u001b[0m     norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(emb, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "added = index.build_from_symbol_dfs(\n",
        "    {s: train_df.loc[s] for s in available_symbols},\n",
        "    lookback=5,\n",
        "    indicator_builder=default_indicator_builder,\n",
        "    timeframe=TimeFrame.day,\n",
        "    show_progress=True,\n",
        ")\n",
        "print(f\"Indexed {added} candidates from training period\")\n",
        "print(f\"Index size (ids) = {len(index.id_to_meta)}; last dates per symbol = {list(index.symbol_last_date.items())[:5]} ...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at TheFinAI/FinSeer and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2025-08-10 02:07:42,822 | INFO | src.retrieval.faiss_index: Loaded index from .alpacium_index (ids=8016 symbols=1)\n"
          ]
        }
      ],
      "source": [
        "# FAISS index: load from .alpacium_index if available; else build and save once\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from src.retrieval.finseer_client import FinSeerEmbedder, FinSeerConfig\n",
        "from src.retrieval.faiss_index import FaissCandidateIndex, default_indicator_builder\n",
        "from src.schemas.timeseries import TimeFrame\n",
        "\n",
        "persist_dir = \".alpacium_index\"\n",
        "\n",
        "# Configure embedder (adjust batch_size/device if desired)\n",
        "embedder = FinSeerEmbedder(FinSeerConfig(batch_size=32))\n",
        "\n",
        "# If id_to_meta.json exists, constructor will auto-load the index and metadata\n",
        "index = FaissCandidateIndex(embedder, persist_dir=persist_dir, auto_persist=False)\n",
        "\n",
        "# Ensure we have symbol->DataFrame if we need to build\n",
        "if not Path(persist_dir, \"id_to_meta.json\").exists():\n",
        "    # Try to derive a symbol->df map from a MultiIndex OHLCV frame if available\n",
        "    symbol_to_df = None\n",
        "    if \"train_df\" in locals() and isinstance(train_df.index, pd.MultiIndex):\n",
        "        symbol_to_df = {sym: df.droplevel(0) if isinstance(df.index, pd.MultiIndex) else df\n",
        "                        for sym, df in train_df.groupby(level=\"symbol\")}\n",
        "    elif \"full_df\" in locals() and isinstance(full_df.index, pd.MultiIndex):\n",
        "        symbol_to_df = {sym: df.droplevel(0) if isinstance(df.index, pd.MultiIndex) else df\n",
        "                        for sym, df in full_df.groupby(level=\"symbol\")}\n",
        "    elif \"symbol_to_df\" in locals():\n",
        "        symbol_to_df = symbol_to_df  # already provided\n",
        "\n",
        "    if symbol_to_df is None:\n",
        "        raise RuntimeError(\"Please provide a symbol->DataFrame mapping as `symbol_to_df` or a MultiIndex `train_df`/`full_df`.\")\n",
        "\n",
        "    lookback = (lookback if \"lookback\" in locals() else 5)\n",
        "    timeframe = (timeframe if \"timeframe\" in locals() else TimeFrame.day)\n",
        "\n",
        "    total = index.build_from_symbol_dfs(\n",
        "        symbol_to_df,\n",
        "        lookback=lookback,\n",
        "        indicator_builder=default_indicator_builder,\n",
        "        timeframe=timeframe,\n",
        "        show_progress=True,\n",
        "    )\n",
        "    index.save(persist_dir)\n",
        "\n",
        "# `index` is ready; proceed to alpha generation cells that use `index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-10 02:06:52,330 | INFO | accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86adee5bd4594c3fbfac340cc460c1b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# 4) Initialize StockLLM generator\n",
        "stockllm = StockLLMGenerator(StockLLMConfig(temperature=0.0, max_new_tokens=64))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping non-indexed symbols (no candidates in retrieval index): ['AMZN', 'AVGO', 'CRM', 'GOOGL', 'META', 'MSFT', 'NVDA', 'ORCL', 'TSLA']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e9dd44f82b0409fa0cb81d79ade4e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating StockLLM signals:   0%|          | 0/246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kaydee647/alpacium/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/home/kaydee647/alpacium/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/home/kaydee647/alpacium/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/home/kaydee647/alpacium/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/home/kaydee647/alpacium/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Restrict alpha generation to symbols that exist in the retrieval index\n",
        "indexed_symbols = sorted([s for s, ids in getattr(index, \"symbol_to_ids\", {}).items() if ids])\n",
        "if len(indexed_symbols) == 0:\n",
        "    print(\"Warning: No indexed symbols found; skipping alpha generation.\")\n",
        "    test_df_for_alpha = test_df.iloc[0:0]\n",
        "else:\n",
        "    # Filter 2024 test data to indexed symbols only\n",
        "    test_df_for_alpha = test_df.loc[(indexed_symbols, slice(None)), :]\n",
        "    missing = sorted(set(test_df.index.get_level_values(0).unique()) - set(indexed_symbols))\n",
        "    if missing:\n",
        "        print(f\"Skipping non-indexed symbols (no candidates in retrieval index): {missing}\")\n",
        "\n",
        "# 5) Generate signals on 2024 only using the trained index\n",
        "alpha_engine = AlphaEngine()\n",
        "alpha_signals = alpha_engine.generate_signals(\n",
        "    historical_data=test_df_for_alpha,\n",
        "    alpha_function=lambda data: stockllm_alpha(\n",
        "        historical_data=data,\n",
        "        index=index,\n",
        "        generator=stockllm,\n",
        "        lookback=5,\n",
        "        top_k=5,\n",
        "        timeframe=TimeFrame.day,\n",
        "        confidence_threshold=0.0,\n",
        "        filter_symbols=indexed_symbols,\n",
        "    ),\n",
        "    parameters=None,\n",
        "    show_progress=False,\n",
        ")\n",
        "print(alpha_signals.signals[[\"movement\", \"prob_rise\", \"prob_fall\", \"prob_freeze\", \"confidence\", \"signal\"]].dropna().head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 6) Backtest with vectorbt on 2024\n",
        "bt_results = run_backtest_vbt(\n",
        "    historical_data=test_df,\n",
        "    alpha_signals=alpha_signals,\n",
        "    initial_capital=1_000_000.0,\n",
        "    transaction_cost=0.001,\n",
        ")\n",
        "print({\n",
        "    \"total_return\": bt_results.total_return,\n",
        "    \"annual_return\": bt_results.annual_return,\n",
        "    \"sharpe_ratio\": bt_results.sharpe_ratio,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 7) Analytics: hit-rate, Brier score, per-symbol breakdown\n",
        "sigs = alpha_signals.signals.copy()\n",
        "# Realized next-day movement from adjusted_close\n",
        "adj = test_df[\"adjusted_close\"].unstack(level=0)\n",
        "next_ret = adj.pct_change().shift(-1)\n",
        "# Long/short correctness based on sign of next day's return\n",
        "realized_move = next_ret.applymap(lambda x: \"rise\" if x > 0 else (\"fall\" if x < 0 else \"freeze\"))\n",
        "realized_move = realized_move.stack().rename(\"realized_movement\")\n",
        "\n",
        "# Align with signals index\n",
        "eval_df = sigs[[\"movement\", \"prob_rise\", \"prob_fall\", \"prob_freeze\", \"confidence\", \"signal\"]].join(realized_move, how=\"left\")\n",
        "\n",
        "def brier_row(row: pd.Series) -> float:\n",
        "    y = {\"rise\": 0.0, \"fall\": 0.0, \"freeze\": 0.0}\n",
        "    if isinstance(row.get(\"realized_movement\"), str) and row[\"realized_movement\"] in y:\n",
        "        y[row[\"realized_movement\"]] = 1.0\n",
        "    p_r = float(row.get(\"prob_rise\", 0.0) or 0.0)\n",
        "    p_f = float(row.get(\"prob_fall\", 0.0) or 0.0)\n",
        "    p_z = float(row.get(\"prob_freeze\", 0.0) or 0.0)\n",
        "    return (y[\"rise\"] - p_r) ** 2 + (y[\"fall\"] - p_f) ** 2 + (y[\"freeze\"] - p_z) ** 2\n",
        "\n",
        "# Classification accuracy on non-null realized\n",
        "mask = eval_df[\"realized_movement\"].notna()\n",
        "overall_acc = (eval_df.loc[mask, \"movement\"] == eval_df.loc[mask, \"realized_movement\"]).mean()\n",
        "brier = eval_df.loc[mask].apply(brier_row, axis=1).mean()\n",
        "\n",
        "# Per-symbol accuracy\n",
        "per_symbol = (\n",
        "    eval_df.loc[mask]\n",
        "    .reset_index()\n",
        "    .groupby(\"symbol\")\n",
        "    .apply(lambda g: pd.Series({\n",
        "        \"n\": len(g),\n",
        "        \"accuracy\": (g[\"movement\"] == g[\"realized_movement\"]).mean(),\n",
        "        \"avg_confidence\": g[\"confidence\"].astype(float).mean(),\n",
        "    }))\n",
        "    .sort_values(\"accuracy\", ascending=False)\n",
        ")\n",
        "\n",
        "# Confidence calibration buckets\n",
        "bins = [0.0, 0.55, 0.7, 0.85, 1.01]\n",
        "labels = [\"<=0.55\", \"0.55-0.7\", \"0.7-0.85\", \">0.85\"]\n",
        "eval_df[\"conf_bin\"] = pd.cut(eval_df[\"confidence\"].astype(float), bins=bins, labels=labels, include_lowest=True)\n",
        "calib = (\n",
        "    eval_df.loc[mask]\n",
        "    .groupby(\"conf_bin\")\n",
        "    .apply(lambda g: pd.Series({\n",
        "        \"n\": len(g),\n",
        "        \"accuracy\": (g[\"movement\"] == g[\"realized_movement\"]).mean(),\n",
        "        \"avg_confidence\": g[\"confidence\"].astype(float).mean(),\n",
        "        \"avg_brier\": g.apply(brier_row, axis=1).mean(),\n",
        "    }))\n",
        ")\n",
        "\n",
        "print(\"\\nAnalytics summary (2024):\")\n",
        "print({\"accuracy\": float(overall_acc), \"brier\": float(brier)})\n",
        "print(\"\\nPer-symbol accuracy (top 10):\")\n",
        "print(per_symbol.head(10))\n",
        "print(\"\\nConfidence calibration:\")\n",
        "print(calib)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8) VectorBT: rich stats and core plots\n",
        "import vectorbt as vbt  # noqa: F401\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "pf = bt_results.portfolio\n",
        "\n",
        "# Full stats table\n",
        "stats = pf.stats()\n",
        "display(stats)\n",
        "\n",
        "# Equity curve with positions\n",
        "fig = pf.plot()\n",
        "fig.update_layout(title='Strategy equity and positions')\n",
        "fig.show()\n",
        "\n",
        "# Drawdowns plot\n",
        "fig = pf.drawdowns.plot()\n",
        "fig.update_layout(title='Strategy drawdowns')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9) Trade analysis (per-symbol, expectancy) and turnover\n",
        "trades = pf.trades\n",
        "\n",
        "# Overall trade stats\n",
        "trade_stats = trades.stats()\n",
        "display(trade_stats)\n",
        "\n",
        "# Per-symbol trade stats (win rate, PF, expectancy)\n",
        "per_symbol_trades = trades.stats(group_by='symbol')\n",
        "display(per_symbol_trades.sort_values('Win Rate [%]', ascending=False).head(10))\n",
        "\n",
        "# Expectancy distribution\n",
        "exp_series = trades.expectancy()\n",
        "fig = exp_series.vbt.histplot(xaxis_title='Expectancy', title='Trade expectancy distribution')\n",
        "fig.show()\n",
        "\n",
        "# Turnover and exposure\n",
        "turnover = pf.turnover()\n",
        "exposure = pf.gross_exposure()\n",
        "fig = vbt.make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
        "turnover.vbt.plot(add_trace_kwargs=dict(row=1, col=1), fig=fig)\n",
        "exposure.vbt.plot(add_trace_kwargs=dict(row=2, col=1), fig=fig)\n",
        "fig.update_layout(title='Turnover and Gross Exposure')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10) Rolling performance and factor exposure proxy\n",
        "# Rolling Sharpe (60d) on aggregated portfolio returns and rolling max drawdown (252d)\n",
        "strat_ret = pf.returns().sum(axis=1)\n",
        "rolling_sharpe = (strat_ret.rolling(60).mean() / strat_ret.rolling(60).std()).mul(np.sqrt(252))\n",
        "\n",
        "# Rolling max drawdown from equity curve\n",
        "equity = pf.value()\n",
        "roll_peak = equity.rolling(252).max()\n",
        "rolling_maxdd = 1.0 - (equity / roll_peak)\n",
        "\n",
        "fig = vbt.make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
        "rolling_sharpe.vbt.plot(add_trace_kwargs=dict(row=1, col=1), fig=fig)\n",
        "fig.update_yaxes(title_text='Rolling Sharpe (60d)', row=1, col=1)\n",
        "rolling_maxdd.vbt.plot(add_trace_kwargs=dict(row=2, col=1), fig=fig)\n",
        "fig.update_yaxes(title_text='Rolling Max DD (252d)', row=2, col=1)\n",
        "fig.update_layout(title='Rolling performance metrics')\n",
        "fig.show()\n",
        "\n",
        "# Beta to market (proxy): regress daily returns vs SPY if available via YF\n",
        "try:\n",
        "    spy = vbt.YFData.download('SPY', period='5y').get('Close').pct_change().rename('mkt')\n",
        "    strat_ret = strat_ret.rename('strat')\n",
        "    joined = pd.concat([strat_ret, spy], axis=1).dropna()\n",
        "    beta = joined.cov().iloc[0,1] / joined.var().iloc[1,0]\n",
        "    alpha = joined['strat'].mean() - beta * joined['mkt'].mean()\n",
        "    print({'market_beta': float(beta), 'alpha_daily_mean': float(alpha)})\n",
        "except Exception as e:\n",
        "    print('Beta calc skipped:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11) Confidence-threshold sweep vs performance\n",
        "# Evaluate how confidence gating impacts returns and accuracy\n",
        "conf_grid = np.linspace(0.0, 0.9, 10)\n",
        "records = []\n",
        "close_w = test_df['close'].unstack(level=0)\n",
        "sig = alpha_signals.signals['signal'].unstack(level=0).reindex(close_w.index).fillna(0.0)\n",
        "probs = alpha_signals.signals['confidence'].unstack(level=0).reindex(close_w.index).fillna(0.0)\n",
        "\n",
        "for thr in conf_grid:\n",
        "    gated = sig.where(probs >= thr, other=0.0)\n",
        "    long_now = gated > 0\n",
        "    long_prev = long_now.shift(1, fill_value=False)\n",
        "    entries = long_now & ~long_prev\n",
        "    exits = ~long_now & long_prev\n",
        "    short_now = gated < 0\n",
        "    short_prev = short_now.shift(1, fill_value=False)\n",
        "    short_entries = short_now & ~short_prev\n",
        "    short_exits = ~short_now & short_prev\n",
        "    n_symbols = close_w.shape[1]\n",
        "    alloc_per_symbol = 1_000_000.0 / max(n_symbols, 1)\n",
        "    pf_thr = vbt.Portfolio.from_signals(\n",
        "        close=close_w,\n",
        "        entries=entries,\n",
        "        exits=exits,\n",
        "        short_entries=short_entries,\n",
        "        short_exits=short_exits,\n",
        "        init_cash=1_000_000.0,\n",
        "        fees=0.001,\n",
        "        size=(alloc_per_symbol / close_w).where(entries, other=0.0),\n",
        "        short_size=(alloc_per_symbol / close_w).where(short_entries, other=0.0),\n",
        "        freq='1D',\n",
        "    )\n",
        "    stats_thr = pf_thr.stats()\n",
        "    tr = float(stats_thr.get('Total Return [%]', np.nan))\n",
        "    sr = float(stats_thr.get('Sharpe Ratio', np.nan))\n",
        "    dd = float(stats_thr.get('Max Drawdown [%]', np.nan))\n",
        "    records.append({'threshold': thr, 'total_return_%': tr, 'sharpe': sr, 'max_dd_%': dd})\n",
        "\n",
        "thr_df = pd.DataFrame.from_records(records).set_index('threshold')\n",
        "display(thr_df)\n",
        "fig = thr_df[['total_return_%', 'sharpe']].vbt.plot(title='Performance vs confidence threshold')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12) Per-symbol contribution and heatmaps\n",
        "# Total return per symbol and turnover heatmap\n",
        "ret_ps = pf.total_return()\n",
        "fig = ret_ps.vbt.barplot(title='Total Return per Symbol')\n",
        "fig.show()\n",
        "\n",
        "heat_perf = pf.total_return().vbt.heatmap(xaxis_title='symbol', title='Total return heatmap')\n",
        "heat_perf.show()\n",
        "\n",
        "# Turnover heatmap\n",
        "turnover_ps = pf.turnover()\n",
        "fig = turnover_ps.vbt.heatmap(title='Turnover heatmap')\n",
        "fig.show()\n",
        "\n",
        "# Correlation of symbol returns\n",
        "sym_returns = pf.assets_returns()\n",
        "fig = sym_returns.corr().vbt.heatmap(title='Correlation of asset returns')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13) Animated chart of signals vs price per symbol\n",
        "# Create a simple animation across symbols showing price and position state\n",
        "from itertools import cycle\n",
        "\n",
        "close_w = test_df['close'].unstack(level=0)\n",
        "position = pf.positions.values  # same shape as close_w\n",
        "symbols_list = list(close_w.columns)\n",
        "\n",
        "# Save a GIF cycling over symbols\n",
        "\n",
        "def plot_symbol(idx_sym):\n",
        "    sym = symbols_list[idx_sym]\n",
        "    s_close = close_w[sym]\n",
        "    s_pos = pd.Series(position[:, idx_sym], index=close_w.index, name='pos')\n",
        "    fig = vbt.make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
        "    s_close.vbt.plot(add_trace_kwargs=dict(row=1, col=1, name='Close'), fig=fig)\n",
        "    s_pos.vbt.plot(add_trace_kwargs=dict(row=2, col=1, name='Position'), fig=fig)\n",
        "    fig.update_layout(template='plotly_dark', width=900, height=500, title=f'{sym}: Close & Position')\n",
        "    return fig\n",
        "\n",
        "vbt.save_animation('symbol_positions.gif', range(len(symbols_list)), plot_symbol, delta=1, fps=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paper-aligned analysis additions\n",
        "\n",
        "From the StockLLM + FinSeer paper in `docs/stockLLM/paper-large.md` and `docs/stockLLM/paper-small.md`, we add:\n",
        "\n",
        "- Calibration and Brier score analysis to match focus on probabilistic movement prediction.\n",
        "- Confidence-threshold gating performance curves to evaluate trade-off of precision vs coverage.\n",
        "- Per-indicator/per-symbol breakdowns to inspect where the alpha works best.\n",
        "- Rolling performance to assess regime sensitivity, esp. during volatile periods.\n",
        "\n",
        "These are implemented in cells 8–13 using vectorbt’s stats, trades, heatmaps, and animation helpers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14) Retrieved indicator occurrences (paper-style)\n",
        "# Sample retrievals across test period to see which indicators are most used\n",
        "from src.schemas import QueryBasic\n",
        "\n",
        "counts = {}\n",
        "sample_dates = (\n",
        "    test_df.index.get_level_values('timestamp')\n",
        "    .unique()\n",
        "    .sort_values()\n",
        ")\n",
        "# downsample dates for speed (every 5th trading day)\n",
        "sample_dates = sample_dates[::5]\n",
        "\n",
        "for sym in available_symbols:\n",
        "    sdf = test_df.loc[sym].sort_index()\n",
        "    dates = [d for d in sample_dates if d in sdf.index]\n",
        "    for as_of in dates:\n",
        "        qb = QueryBasic.from_dataframe(sym, test_df, as_of=as_of.date(), lookback=5, timeframe=TimeFrame.day)\n",
        "        hits = index.query(qb, top_k=5)\n",
        "        for h in hits:\n",
        "            ind = h.get('indicator', 'unknown')\n",
        "            counts[ind] = counts.get(ind, 0) + 1\n",
        "\n",
        "ind_df = pd.Series(counts, name='occurrences').sort_values(ascending=False)\n",
        "display(ind_df.head(20))\n",
        "\n",
        "fig = ind_df.head(30).vbt.barplot(title='Top retrieved indicators (sampled)')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15) Accuracy vs confidence threshold and reliability curve\n",
        "# Uses eval_df from cell 8\n",
        "thr_records = []\n",
        "for thr in conf_grid:\n",
        "    sel = eval_df['confidence'].astype(float) >= thr\n",
        "    sub = eval_df.loc[sel & eval_df['realized_movement'].notna()]\n",
        "    acc = (sub['movement'] == sub['realized_movement']).mean() if len(sub) else np.nan\n",
        "    thr_records.append({'threshold': thr, 'accuracy': acc, 'coverage': len(sub)})\n",
        "acc_df = pd.DataFrame(thr_records).set_index('threshold')\n",
        "display(acc_df)\n",
        "fig = acc_df[['accuracy']].vbt.plot(title='Classification accuracy vs confidence threshold')\n",
        "fig.show()\n",
        "\n",
        "# Reliability (calibration) curve\n",
        "calib_points = (\n",
        "    eval_df.loc[eval_df['realized_movement'].notna()]\n",
        "    .groupby('conf_bin')\n",
        "    .apply(lambda g: pd.Series({'avg_conf': g['confidence'].astype(float).mean(),\n",
        "                                'emp_acc': (g['movement'] == g['realized_movement']).mean()}))\n",
        "    .dropna()\n",
        ")\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=calib_points['avg_conf'], y=calib_points['emp_acc'], mode='lines+markers', name='Empirical'))\n",
        "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Perfect', line=dict(dash='dash')))\n",
        "fig.update_layout(title='Reliability curve (confidence vs empirical accuracy)', xaxis_title='Average confidence', yaxis_title='Empirical accuracy')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save train and test DataFrames to disk\n",
        "import os\n",
        "\n",
        "out_dir = \"artifacts\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "train_df.to_parquet(os.path.join(out_dir, \"train_df.parquet\"))\n",
        "test_df.to_parquet(os.path.join(out_dir, \"test_df.parquet\"))\n",
        "\n",
        "print(\"Saved:\", os.path.join(out_dir, \"train_df.parquet\"), \"and\", os.path.join(out_dir, \"test_df.parquet\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
