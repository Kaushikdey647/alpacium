{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Backtesting StockLLM Alpha on US Mega-cap Tech (Daily)\n",
        "\n",
        "Pipeline:\n",
        "- Fetch last 5 years of daily bars from Alpaca for 10 large-cap US tech stocks\n",
        "- Build a FAISS candidate index using the first 4 years (2020-01 to 2023-12) with paper-aligned indicators (OHLCV + RSI + MACD_hist)\n",
        "- Run the StockLLM alpha on the last 1 year (2024-01 to 2024-12) only\n",
        "- Backtest with vectorbt and run analytics (performance, hit rate, per-symbol breakdown, calibration/Brier)\n",
        "\n",
        "Notes:\n",
        "- Requires `alpaca-py`, `transformers`, `torch`, and `faiss-cpu` (CPU fallback for FAISS implemented)\n",
        "- StockLLM and FinSeer models will be downloaded on first run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.utils.logging import configure_logging\n",
        "configure_logging(level=\"INFO\", use_rich=False)\n",
        "\n",
        "from src.schemas import TimeFrame\n",
        "from src.adapters.alpaca_data import AlpacaMarketData, AlpacaMarketDataConfig\n",
        "from src.retrieval.finseer_client import FinSeerEmbedder, FinSeerConfig\n",
        "from src.retrieval.faiss_index import FaissCandidateIndex, default_indicator_builder\n",
        "from src.llm.stockllm_client import StockLLMGenerator, StockLLMConfig\n",
        "from src.alphas.stockllm_alpha import stockllm_alpha\n",
        "from src.engines.alpha_engine import AlphaEngine\n",
        "from src.engines.vbt_engine import run_backtest_vbt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 0) Symbols and date ranges\n",
        "symbols = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\",\n",
        "    \"META\", \"TSLA\", \"AVGO\", \"ORCL\", \"CRM\",\n",
        "]\n",
        "fetch_start = datetime(2020, 1, 1)\n",
        "fetch_end = datetime(2024, 12, 31)\n",
        "train_start = datetime(2020, 1, 1)\n",
        "train_end = datetime(2023, 12, 31)\n",
        "test_start = datetime(2024, 1, 1)\n",
        "test_end = datetime(2024, 12, 31)\n",
        "\n",
        "# 1) Fetch daily OHLCV from Alpaca\n",
        "# Reads keys from env (ALPACA_API_KEY, ALPACA_SECRET_KEY) or env.py if available\n",
        "api_key = os.getenv(\"ALPACA_API_KEY\")\n",
        "secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
        "if (api_key is None or secret_key is None):\n",
        "    try:\n",
        "        from env import paper_api_key as api_key, paper_secret_key as secret_key  # type: ignore\n",
        "    except Exception:\n",
        "        api_key = None\n",
        "        secret_key = None\n",
        "\n",
        "md = AlpacaMarketData(AlpacaMarketDataConfig(api_key=api_key, secret_key=secret_key, use_paper=True))\n",
        "print(f\"Using Alpaca API key={bool(api_key)} secret={bool(secret_key)}\")\n",
        "sym_to_df = md.get_stock_bars(\n",
        "    symbols=symbols,\n",
        "    timeframe=TimeFrame.day,\n",
        "    start=fetch_start,\n",
        "    end=fetch_end,\n",
        ")\n",
        "print(f\"Fetched {len(sym_to_df)} symbols: {[k for k in sym_to_df.keys()]}\")\n",
        "sym_to_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Filter to only symbols that returned data\n",
        "available_symbols = [s for s in symbols if s in sym_to_df and len(sym_to_df[s]) > 0]\n",
        "if len(available_symbols) < len(symbols):\n",
        "    missing = sorted(set(symbols) - set(available_symbols))\n",
        "    print(f\"Warning: missing data for symbols: {missing}\")\n",
        "\n",
        "# Combine to one MultiIndex DataFrame\n",
        "all_df = pd.concat({s: sym_to_df[s] for s in available_symbols}, names=[\"symbol\", \"timestamp\"]).sort_index()\n",
        "\n",
        "# 2) Split periods\n",
        "train_df = all_df.loc[(slice(None), slice(train_start, train_end)), :]\n",
        "test_df = all_df.loc[(slice(None), slice(test_start, test_end)), :]\n",
        "print({\n",
        "    \"train_span_days\": (train_end - train_start).days + 1,\n",
        "    \"test_span_days\": (test_end - test_start).days + 1,\n",
        "    \"train_rows\": len(train_df),\n",
        "    \"test_rows\": len(test_df),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 3) Build FinSeer+FAISS index on 2020-01..2023-12\n",
        "embedder = FinSeerEmbedder(FinSeerConfig())\n",
        "index = FaissCandidateIndex(\n",
        "    embedder,\n",
        "    normalize=True,\n",
        "    use_gpu=True,\n",
        "    persist_dir=\"./.alpacium_index\",\n",
        "    auto_persist=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "added = index.build_from_symbol_dfs(\n",
        "    {s: train_df.loc[s] for s in available_symbols},\n",
        "    lookback=5,\n",
        "    indicator_builder=default_indicator_builder,\n",
        "    timeframe=TimeFrame.day,\n",
        "    show_progress=True,\n",
        ")\n",
        "print(f\"Indexed {added} candidates from training period\")\n",
        "print(f\"Index size (ids) = {len(index.id_to_meta)}; last dates per symbol = {list(index.symbol_last_date.items())[:5]} ...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 4) Initialize StockLLM generator\n",
        "stockllm = StockLLMGenerator(StockLLMConfig(temperature=0.0, max_new_tokens=64))\n",
        "\n",
        "# 5) Generate signals on 2024 only using the trained index\n",
        "alpha_engine = AlphaEngine()\n",
        "alpha_signals = alpha_engine.generate_signals(\n",
        "    historical_data=test_df,\n",
        "    alpha_function=lambda data: stockllm_alpha(\n",
        "        historical_data=data,\n",
        "        index=index,\n",
        "        generator=stockllm,\n",
        "        lookback=5,\n",
        "        top_k=5,\n",
        "        timeframe=TimeFrame.day,\n",
        "        confidence_threshold=0.0,\n",
        "    ),\n",
        "    parameters=None,\n",
        "    show_progress=False,\n",
        ")\n",
        "print(alpha_signals.signals[[\"movement\", \"prob_rise\", \"prob_fall\", \"prob_freeze\", \"confidence\", \"signal\"]].dropna().head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 6) Backtest with vectorbt on 2024\n",
        "bt_results = run_backtest_vbt(\n",
        "    historical_data=test_df,\n",
        "    alpha_signals=alpha_signals,\n",
        "    initial_capital=1_000_000.0,\n",
        "    transaction_cost=0.001,\n",
        ")\n",
        "print({\n",
        "    \"total_return\": bt_results.total_return,\n",
        "    \"annual_return\": bt_results.annual_return,\n",
        "    \"sharpe_ratio\": bt_results.sharpe_ratio,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 7) Analytics: hit-rate, Brier score, per-symbol breakdown\n",
        "sigs = alpha_signals.signals.copy()\n",
        "# Realized next-day movement from adjusted_close\n",
        "adj = test_df[\"adjusted_close\"].unstack(level=0)\n",
        "next_ret = adj.pct_change().shift(-1)\n",
        "# Long/short correctness based on sign of next day's return\n",
        "realized_move = next_ret.applymap(lambda x: \"rise\" if x > 0 else (\"fall\" if x < 0 else \"freeze\"))\n",
        "realized_move = realized_move.stack().rename(\"realized_movement\")\n",
        "\n",
        "# Align with signals index\n",
        "eval_df = sigs[[\"movement\", \"prob_rise\", \"prob_fall\", \"prob_freeze\", \"confidence\", \"signal\"]].join(realized_move, how=\"left\")\n",
        "\n",
        "def brier_row(row: pd.Series) -> float:\n",
        "    y = {\"rise\": 0.0, \"fall\": 0.0, \"freeze\": 0.0}\n",
        "    if isinstance(row.get(\"realized_movement\"), str) and row[\"realized_movement\"] in y:\n",
        "        y[row[\"realized_movement\"]] = 1.0\n",
        "    p_r = float(row.get(\"prob_rise\", 0.0) or 0.0)\n",
        "    p_f = float(row.get(\"prob_fall\", 0.0) or 0.0)\n",
        "    p_z = float(row.get(\"prob_freeze\", 0.0) or 0.0)\n",
        "    return (y[\"rise\"] - p_r) ** 2 + (y[\"fall\"] - p_f) ** 2 + (y[\"freeze\"] - p_z) ** 2\n",
        "\n",
        "# Classification accuracy on non-null realized\n",
        "mask = eval_df[\"realized_movement\"].notna()\n",
        "overall_acc = (eval_df.loc[mask, \"movement\"] == eval_df.loc[mask, \"realized_movement\"]).mean()\n",
        "brier = eval_df.loc[mask].apply(brier_row, axis=1).mean()\n",
        "\n",
        "# Per-symbol accuracy\n",
        "per_symbol = (\n",
        "    eval_df.loc[mask]\n",
        "    .reset_index()\n",
        "    .groupby(\"symbol\")\n",
        "    .apply(lambda g: pd.Series({\n",
        "        \"n\": len(g),\n",
        "        \"accuracy\": (g[\"movement\"] == g[\"realized_movement\"]).mean(),\n",
        "        \"avg_confidence\": g[\"confidence\"].astype(float).mean(),\n",
        "    }))\n",
        "    .sort_values(\"accuracy\", ascending=False)\n",
        ")\n",
        "\n",
        "# Confidence calibration buckets\n",
        "bins = [0.0, 0.55, 0.7, 0.85, 1.01]\n",
        "labels = [\"<=0.55\", \"0.55-0.7\", \"0.7-0.85\", \">0.85\"]\n",
        "eval_df[\"conf_bin\"] = pd.cut(eval_df[\"confidence\"].astype(float), bins=bins, labels=labels, include_lowest=True)\n",
        "calib = (\n",
        "    eval_df.loc[mask]\n",
        "    .groupby(\"conf_bin\")\n",
        "    .apply(lambda g: pd.Series({\n",
        "        \"n\": len(g),\n",
        "        \"accuracy\": (g[\"movement\"] == g[\"realized_movement\"]).mean(),\n",
        "        \"avg_confidence\": g[\"confidence\"].astype(float).mean(),\n",
        "        \"avg_brier\": g.apply(brier_row, axis=1).mean(),\n",
        "    }))\n",
        ")\n",
        "\n",
        "print(\"\\nAnalytics summary (2024):\")\n",
        "print({\"accuracy\": float(overall_acc), \"brier\": float(brier)})\n",
        "print(\"\\nPer-symbol accuracy (top 10):\")\n",
        "print(per_symbol.head(10))\n",
        "print(\"\\nConfidence calibration:\")\n",
        "print(calib)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
